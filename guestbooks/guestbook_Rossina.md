Dear all,

This is the link to my project titled ["Complexity measures and proficiency"](https://github.com/Data-Sci-2021/Complexity-measures-and-proficiency).

I am having trouble convincing codes to work properly because all my texts are in Russian.


Shaohua's comments: 

Rossina, this project looks interesting. When I read your project about linguistic complexity and language proficiency, it strikes to me that you would probably heavily use computational toolkits for those calculations, which is exactly what this class could help. Besides, I am looking forward to seeing the results - my intuition is that higher proficiency leads to more complexity but I am sure that there should be lots of theoretical complications there. 


What was done well: It is nice that you already have two corpora at hand for your analyses. Also it looks good that you have started off to create codes for calculating some complexity metrics.


One suggestion for improvement: I am curious about how you would justify the use of these two corpora for your statistical analyses, for example, regression/correlation, because I feel like the the two corpora are from two different populations? In addition, it would be nice if you could specify what is standardization of texts used for - would like to learn its theoretical underpinnings.


One thing I learned: The topic itself is intriguing for me - if complexity measures are highly correlated with learners' overall language proficiency, then those measures could be directly used for approximating proficiency. If so, they would be very useful for SLA. 